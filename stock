#-*-coding:utf-8-*-
import pprint
import requests
urldict={}
import os,json
try:
    os.mkdir('./output')
except:
    pass

#从巨潮资讯解析出pdf的真实下载地址
f=open('stkcd.csv','r',encoding='utf-8')
fout=open('./output/urls.csv','w')
for line in f:
    stkcd=str(line[:6])
    #这一行把“招股说明书”换成　“年报”　“半年报”　之类的，即可批量下载其他的公告
    response=requests.get('http://www.cninfo.com.cn/cninfo-new/fulltextSearch/full?searchkey='+stkcd+'+招股说明书&sdate=&edate=&isfulltext=false&sortName=nothing&sortType=desc&pageNum=1')
    #dict=response.json()
    dict=json.loads(response.text)
    for i in dict['announcements']:
        if '摘要' not in i['announcementTitle']:
            print(i['announcementTitle'])
            url='http://www.cninfo.com.cn/'+i['adjunctUrl']
            print(url)
            secname=i['secName']
            date=i['adjunctUrl'][10:20]
            urldict.update({stkcd+'-'+secname+'-'+date:url})
            csvtowrite=stkcd+','+'secname'+','+date+','+url+'\n'
            fout.write(csvtowrite)
pprint.pprint(urldict)
fout.close()

#根据解析出的pdf地址下载到output，并重命名成有规律的文件
import urllib.request
for name in urldict:
    url=urldict[name]
    response=urllib.request.urlopen(url)
    file = open('./output/'+name+'.pdf','wb')
    file.write(response.read())
    file.close()
    print(name)
